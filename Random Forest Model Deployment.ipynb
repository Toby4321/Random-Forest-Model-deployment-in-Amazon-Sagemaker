{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toby Adjuik\n",
    "adjuiktoby@gmail.com\n",
    "\n",
    "Department of Biosystems and Agricultural Engineering\n",
    "\n",
    "University of Kentucky\n",
    "\n",
    "February 10, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model deployment in Amazon Sagemaker.\n",
    "\n",
    "In this notebook, I show how I trained and deployed a machine learning model using AWS SageMaker.\n",
    "This notebook was created and run in an Amazon Sagemaker notebook instance. This demonstration is from a project I worked on titled \"Machine Learning Approach to Simulating CO2 Fluxes in Cropping Systems\".\n",
    "\n",
    "#### Resources needed\n",
    "1. A dataset: The dataset used in this project was the GRACEnet dataset.The\n",
    "main purpose of the GRACEnet database is to aggregate information from many studies so\n",
    "that methods for quantifying GHG emissions and other environmental impacts of cropped\n",
    "and grazed systems can be developed, and to provide scientific evidence for carbon trading\n",
    "programs that can help reduce GHG emissions.\n",
    "\n",
    "The original uncleaned and unprocessed data used in this project can be found at: https://data.nal.usda.gov/dataset/gracenet-greenhouse-gas-reduction-through-agricultural-carbon-enhancement-network\n",
    "\n",
    "2. An algorithm: I used the Random Forest algorithm in scikit-learn provided by Amazon SageMaker to train the model using the GRACEnet dataset to predict the CO2 flux in the cropping systems.\n",
    "\n",
    "#### Resources from Amazon SageMaker\n",
    "\n",
    "A few resources needed for storing your data and running the code in Amazon SageMaker:\n",
    "\n",
    "1. An Amazon Simple Storage Service (Amazon S3) bucket to store the training data and the model artifacts that Amazon SageMaker creates when it trains the model.\n",
    "\n",
    "2. An Amazon SageMaker notebook instance to prepare and process data and to train and deploy a machine learning model.\n",
    "\n",
    "3. A Jupyter notebook to use with the notebook instance to prepare your training data and train and deploy the model.\n",
    "\n",
    "Detailed description of this work is available in our paper: Adjuik, T.A., Davis, S.C. Machine Learning Approach to Simulate Soil CO2 Fluxes under Cropping Systems. Agronomy 2022, 12, 197, doi: https://doi.org/10.3390/agronomy12010197"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # library for data manipulation and analysis.\n",
    "import numpy as np # library for scientific computing, provides high-performance, easy to use structures and data analysis tools. \n",
    "import matplotlib.pyplot as plt # Plotting library\n",
    "import seaborn as sns # data visualization library\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "#Uploading a cleaned version of the dataset. To learn more about the data cleaning and manipulation steps for this data, see\n",
    "# my repository titled \"MLSoilCO2Flux\"\n",
    "data = pd.read_csv(\"New_GHG_Data_Deployment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7863, 11)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes for Target and Predictors\n",
    " \n",
    "x_data = pd.DataFrame(np.c_[data ['Air_Temp_DEGC'],data ['Soil_Temp_DEGC'],data ['Soil_Classification'],data ['Crop'],data ['Fert_Ammend_Class']], columns = ['Air_Temp_DEGC','Soil_Temp_DEGC','Soil_Classification','Crop','Fert_Ammend_Class'])\n",
    "y_data = data ['Carbon_dioxide'] # Create dataset with CO2 flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.20, random_state=10)                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the X_trainset is (6290, 5)\n",
      "The shape of the y_trainset is (6290,)\n",
      "The shape of the X_testset is (1573, 5)\n",
      "The shape of the y_testset is (1573,)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the X_trainset is\",x_train.shape) # The shape of the X_trainset\n",
    "print(\"The shape of the y_trainset is\", y_train.shape) # The shape of the y_trainset\n",
    "\n",
    "print(\"The shape of the X_testset is\", x_test.shape) # The shape of the X_testset\n",
    "print(\"The shape of the y_testset is\", y_test.shape) # The shape of the y_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Air_Temp_DEGC</th>\n",
       "      <th>Soil_Temp_DEGC</th>\n",
       "      <th>Soil_Classification</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Fert_Ammend_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>12.97</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>0.00</td>\n",
       "      <td>20.388889</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Air_Temp_DEGC  Soil_Temp_DEGC  Soil_Classification  Crop  \\\n",
       "16             0.00        0.000000                  6.0   0.0   \n",
       "1858          12.97        0.000000                  1.0   1.0   \n",
       "211            0.00        0.000000                  6.0   0.0   \n",
       "4241           0.00       20.388889                  8.0   1.0   \n",
       "6214           0.00        0.000000                  4.0   4.0   \n",
       "\n",
       "      Fert_Ammend_Class  \n",
       "16                  3.0  \n",
       "1858                2.0  \n",
       "211                 0.0  \n",
       "4241                3.0  \n",
       "6214                3.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Air_Temp_DEGC',\n",
       " 'Soil_Temp_DEGC',\n",
       " 'Soil_Classification',\n",
       " 'Crop',\n",
       " 'Fert_Ammend_Class']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get variable/feature names\n",
    "feature_names=list(x_data.columns.values)\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = pd.DataFrame(x_train, columns=feature_names)# Asssign feature names to the training data set\n",
    "trainX['target'] = y_train\n",
    "\n",
    "testX = pd.DataFrame(x_test, columns=feature_names)# Asssign feature names to the testing data set\n",
    "testX['target'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Air_Temp_DEGC</th>\n",
       "      <th>Soil_Temp_DEGC</th>\n",
       "      <th>Soil_Classification</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Fert_Ammend_Class</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>896.902655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>12.97</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2453.816056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>636.547423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>0.00</td>\n",
       "      <td>20.388889</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4494.138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Air_Temp_DEGC  Soil_Temp_DEGC  Soil_Classification  Crop  \\\n",
       "16             0.00        0.000000                  6.0   0.0   \n",
       "1858          12.97        0.000000                  1.0   1.0   \n",
       "211            0.00        0.000000                  6.0   0.0   \n",
       "4241           0.00       20.388889                  8.0   1.0   \n",
       "6214           0.00        0.000000                  4.0   4.0   \n",
       "\n",
       "      Fert_Ammend_Class       target  \n",
       "16                  3.0   896.902655  \n",
       "1858                2.0  2453.816056  \n",
       "211                 0.0   636.547423  \n",
       "4241                3.0  4494.138000  \n",
       "6214                3.0     0.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.to_csv('GHG_train.csv')# Save the training dataset\n",
    "testX.to_csv('GHG_test.csv')# Save the testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion\n",
    "The training and testing files are then copied to S3 for Amazon SageMaker's managed training to pickup.This should be within the same region as the Notebook Instance, training, and hosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket toby-s3-bucket-name\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tarfile\n",
    "\n",
    "import boto3 # AWS SDK for python. Provides low-level access to AWS services\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "\n",
    "m_boto3 = boto3.client('sagemaker') \n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "bucket = 'bucket-name'  #  Bucket is a logical unit of storage in AWS S3\n",
    "\n",
    "print('Using bucket ' + bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send data to S3. SageMaker will take training data from s3\n",
    "trainpath = sess.upload_data(\n",
    "    path='GHG_train.csv', bucket=bucket,\n",
    "    key_prefix='sagemaker/sklearncontainer')\n",
    "\n",
    "testpath = sess.upload_data(\n",
    "    path='GHG_test.csv', bucket=bucket,\n",
    "    key_prefix='sagemaker/sklearncontainer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare a Scikit-learn Training Script\n",
    "\n",
    "Here, we write the scitkit-learn training script that will be used to train the random forest model.\n",
    "The training script is similar to a training script you might run outside of SageMaker, but you can access useful properties about the training environment through various environment variables. For example:\n",
    "\n",
    "- SM_MODEL_DIR:  A string that represents the path where the training job writes the model artifacts to. After training, artifacts in this directory are uploaded to S3 for model hosting.\n",
    "\n",
    "- SM_OUTPUT_DATA_DIR: A string representing the filesystem path to write output artifacts to. Output artifacts may include checkpoints, graphs, and other files to save, not including model artifacts. These artifacts are compressed and uploaded to S3 to the same S3 prefix as the model artifacts.\n",
    "\n",
    "Supposing two input channels, ‘train’ and ‘test’, were used in the call to the Scikit-learn estimator’s fit() method, the following will be set, following the format “SMCHANNEL[channel_name]”:\n",
    "\n",
    "- SM_CHANNEL_TRAIN: A string representing the path to the directory containing data in the ‘train’ channel\n",
    "\n",
    "- SM_CHANNEL_TEST: Same as above, but for the ‘test’ channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "from sklearn.metrics import explained_variance_score, r2_score\n",
    "\n",
    "\n",
    "\n",
    "# inference functions ---------------\n",
    "def model_fn(model_dir):\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "\n",
    "if __name__ =='__main__':\n",
    "\n",
    "    print('extracting arguments')\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    parser.add_argument('--n-estimators', type=int, default=100)\n",
    "    parser.add_argument('--max_leaf_nodes', type=int, default=10)\n",
    "    \n",
    "\n",
    "#Fit model to training set\n",
    "    \n",
    "\n",
    "    # Data, model, and output directories\n",
    "   \n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n",
    "    parser.add_argument('--train-file', type=str, default='GHG_train.csv')\n",
    "    parser.add_argument('--test-file', type=str, default='GHG_test.csv')\n",
    "    \n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    print('reading data')\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "\n",
    "\n",
    "    \n",
    "    print('building training and testing datasets')\n",
    "    attributes = ['Air_Temp_DEGC', 'Soil_Temp_DEGC', 'Soil_Classification',\n",
    "       'Crop', 'Fert_Ammend_Class']\n",
    "    X_train = train_df[attributes]\n",
    "    X_test = test_df[attributes]\n",
    "    y_train = train_df['target']\n",
    "    y_test = test_df['target']\n",
    "    \n",
    "    # train\n",
    "    print('training model')\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=args.n_estimators,\n",
    "        max_leaf_nodes =args.max_leaf_nodes,\n",
    "        n_jobs=-1)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "     \n",
    "    # persist model\n",
    "    path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(model, path)\n",
    "    print('model persisted at ' + path)\n",
    "    \n",
    "    # print explained_variance_score \n",
    "    print('validating model')\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"Explained Variance Score is \" + str(explained_variance_score(y_test, predictions).round(2)))\n",
    "    print(\"R2 score : %.2f\" % r2_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Training\n",
    "Script arguments allows us to remove from the script any SageMaker-specific configuration, and run locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting arguments\n",
      "reading data\n",
      "building training and testing datasets\n",
      "training model\n",
      "model persisted at ./model.joblib\n",
      "validating model\n",
      "Explained Variance Score is 0.72\n",
      "R2 score : 0.72\n"
     ]
    }
   ],
   "source": [
    "! python script.py --n-estimators 100 \\\n",
    "                   --max-leaf-nodes 10 \\\n",
    "                   --model-dir ./ \\\n",
    "                   --train ./ \\\n",
    "                   --test ./ \\\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Training - Launching a training job with the Python SDK\n",
    "### Create an Estimator\n",
    "You run Scikit-learn training scripts on SageMaker by creating SKLearn Estimators. Call the fit method on a SKLearn Estimator to start a SageMaker training job. The following code sample shows how you train a custom Scikit-learn script named “script.py”, passing in two hyperparameters ('n-estimators', 'max_leaf_nodes'), and using two input channel directories (‘train’ and ‘test’)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "#We use the Estimator from the SageMaker Python SDK\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point='script.py',\n",
    "    role = get_execution_role(),\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.m4.xlarge',\n",
    "    framework_version='0.23-1',\n",
    "    base_job_name='rf-scikit',\n",
    "    hyperparameters = {'n-estimators': 500,\n",
    "                       'max_leaf_nodes': 16 \n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch training job, with asynchronous call\n",
    "sklearn_estimator.fit({'train':trainpath, 'test': testpath}, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to a real-time endpoint\n",
    "#### Deploy with Python SDK\n",
    "An Estimator could be deployed directly after training, with an Estimator.deploy() but here we are using the more extensive process of creating a model from s3 artifacts, that could be used to deploy a model that was trained in a different session or even out of SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the estimator finishes training, we deploy it to a SageMaker endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-02-08 19:54:25 Starting - Preparing the instances for training\n",
      "2022-02-08 19:54:25 Downloading - Downloading input data\n",
      "2022-02-08 19:54:25 Training - Training image download completed. Training in progress.\n",
      "2022-02-08 19:54:25 Uploading - Uploading generated training model\n",
      "2022-02-08 19:54:25 Completed - Training job completed\n",
      "Model artifact persisted at s3://sagemaker-us-east-1-422337765573/rf-scikit-2022-02-08-19-49-16-202/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "sklearn_estimator.latest_training_job.wait(logs='None')\n",
    "artifact = m_boto3.describe_training_job(\n",
    "    TrainingJobName=sklearn_estimator.latest_training_job.name)['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "print('Model artifact persisted at ' + artifact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "predictor = sklearn_estimator.deploy(instance_type='ml.m4.xlarge',initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke with the Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4067.34661881 7211.95004853  385.64980311 ... 4104.57903344  385.64980311\n",
      "  385.64980311]\n"
     ]
    }
   ],
   "source": [
    "print(predictor.predict(testX[feature_names]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(testX[feature_names])# Making predictions with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score : 0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(\"R2 score : %.2f\" % r2_score(testX['target'],predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the evaluation metrics, the trained model attained an R2 of 0.77. This score can be improved with furthur\n",
    "hyperparameter tuning, however I chose to use two hyperparameters ('n-estimators', 'max_leaf_nodes). It is possible to implement \n",
    "automatic hyperparameter tuning using \"GridSearch\" or \"RandomSearch\" packages provided in scikit learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting the endpoint !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)\n",
    "# bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
    "# bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to come back to this notebook after you deployed the SageMaker endpoint, you can use the following snippet of code to invoke it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn_predictor = Predictor(endpoint_name='randomforestregressor-endpoint',\n",
    "#                               sagemaker_session=sess,\n",
    "#                               serializer=NumpySerializer(),\n",
    "#                               deserializer=NumpyDeserializer())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project,\n",
    "I demonstrated the application of Random Forest to predict\n",
    "soil CO2 fluxes with open source data from the GRACEnet database. Prediction R2 value was 0.77\n",
    "\n",
    "#### Summary steps\n",
    "\n",
    "1. Upload  and prepare data\n",
    "2. Ingested Data\n",
    "3. Trained the RF Model\n",
    "4. Launched a training job with the Python SDK\n",
    "5. Deployed the Model to Amazon SageMaker.\n",
    "6. Validated the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "1. Sriramya Kannepalli (February 10, 2022) Random Forest and XGBoost on Amazon SageMaker and AWS Lambda:\n",
    "https://medium.com/analytics-vidhya/random-forest-and-xgboost-on-amazon-sagemaker-and-aws-lambda-29abd9467795\n",
    "\n",
    "\n",
    "2. AmazonSagemaker Examples (February 10, 2022) Develop, Train, Optimize and Deploy Scikit-Learn Random Forest:\n",
    "https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-python-sdk/scikit_learn_randomforest/Sklearn_on_SageMaker_end2end.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
